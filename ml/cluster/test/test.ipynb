{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 转换数据\r\n",
    "import pandas as pd\r\n",
    "import json\r\n",
    "\r\n",
    "# 读取 CSV 文件\r\n",
    "df = pd.read_csv('../data/origin_data.csv')\r\n",
    "# 去除空数据\r\n",
    "df = df[df['data'] != '{}']\r\n",
    "\r\n",
    "# 处理第二列数据\r\n",
    "def expand_column(row):\r\n",
    "    data = json.loads(row['data'])\r\n",
    "    for key, value in data.items():\r\n",
    "        if int(key) <= 0:\r\n",
    "            continue\r\n",
    "        row[key] = value\r\n",
    "    return row\r\n",
    "\r\n",
    "df = df.apply(expand_column, axis=1)\r\n",
    "\r\n",
    "# 删除原始数据列\r\n",
    "df = df.drop('data', axis=1)\r\n",
    "df = df.drop('user_id', axis=1)\r\n",
    "\r\n",
    "# 空数据\r\n",
    "df = df.fillna(0)\r\n",
    "\r\n",
    "# 保存结果\r\n",
    "df.to_csv('../data/test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import json\r\n",
    "import random\r\n",
    "\r\n",
    "df = pd.read_csv('../data/test_data.csv')\r\n",
    "\r\n",
    "data = df.values\r\n",
    "\r\n",
    "\r\n",
    "for num in range(10):\r\n",
    "    for idx in range(len(data)):\r\n",
    "        value = data[idx]\r\n",
    "        #print(\"oldValue\",value)\r\n",
    "        newValue = []\r\n",
    "        for jdx in range(len(value)):\r\n",
    "            newValue.append(int(value[jdx]) + random.randint(0, 10000))\r\n",
    "        #print('newValue',newValue) \r\n",
    "        df.loc[len(df.index)] = newValue\r\n",
    "    print(df.values)\r\n",
    "\r\n",
    "df.to_csv('../data/test_data1.csv', index=False)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data\n",
      "[[ 31703.  24591. 116859. 302925.   4256.]\n",
      " [ 59012.   1796.  88106.  47448.  13043.]\n",
      " [118025.   3593. 176212.  94897.  26087.]\n",
      " [118025.   3593. 176212.  94897.  26087.]\n",
      " [     0.   1322.  20649.  35339.   3721.]\n",
      " [118025.   3593. 176212.  94897.  26087.]]\n",
      "data_scaled\n",
      "[[-0.90103373  2.22188671 -0.1525839   2.15167392 -1.22817505]\n",
      " [-0.32108786 -0.56458879 -0.64835511 -0.72347564 -0.3501244 ]\n",
      " [ 0.93213803 -0.34492235  0.87080528 -0.18948247  0.95331166]\n",
      " [ 0.93213803 -0.34492235  0.87080528 -0.18948247  0.95331166]\n",
      " [-1.57429251 -0.62253086 -1.81147683 -0.85975086 -1.28163552]\n",
      " [ 0.93213803 -0.34492235  0.87080528 -0.18948247  0.95331166]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\r\n",
    "from sklearn.metrics import silhouette_score\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib import colors as mcolors\r\n",
    "import joblib\r\n",
    "\r\n",
    "def k_means(k, data_pca):\r\n",
    "    # 创建 KMeans 模型，并将数据聚类为k组\r\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(data_pca)\r\n",
    "\r\n",
    "    # 获取聚类结果\r\n",
    "    labels = kmeans.labels_\r\n",
    "\r\n",
    "    # 获取聚类中心\r\n",
    "    cluster_centers = kmeans.cluster_centers_\r\n",
    "\r\n",
    "    # print(\"聚类结果：\", labels)\r\n",
    "    # print(\"聚类中心：\", cluster_centers)\r\n",
    "\r\n",
    "    score = silhouette_score(data_pca, labels)\r\n",
    "    # print(f\"Silhouette Coefficient: {score}\")\r\n",
    "    # 可视化结果\r\n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\r\n",
    "    colors = list(mcolors.TABLEAU_COLORS.values())\r\n",
    "\r\n",
    "    for i in range(n_clusters):\r\n",
    "        plt.scatter(data_pca[labels==i, 0], data_pca[labels==i, 1], c=colors[i])\r\n",
    "\r\n",
    "    plt.legend()\r\n",
    "    plt.show()\r\n",
    "    return score\r\n",
    "\r\n",
    "\r\n",
    "# 读取数据\r\n",
    "df = pd.read_csv('../data/test_data.csv')\r\n",
    "data = df.values\r\n",
    "print('data')\r\n",
    "print(data)\r\n",
    "\r\n",
    "scaler = StandardScaler()\r\n",
    "data_scaled = scaler.fit_transform(data)\r\n",
    "print('data_scaled')\r\n",
    "print(data_scaled)\r\n",
    "\r\n",
    "pca = PCA(n_components=2)\r\n",
    "data_pca = pca.fit_transform(data_scaled)\r\n",
    "\r\n",
    "# for k in range(2, 3):\r\n",
    "#     score = k_means(k, data_pca)\r\n",
    "#     print('k=', k, 'score=', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\r\n",
    "from sklearn.metrics import silhouette_score\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib import colors as mcolors\r\n",
    "import joblib\r\n",
    "\r\n",
    "\r\n",
    "keans = joblib.load('../model/kmeans_model.pkl')\r\n",
    "\r\n",
    "df = pd.read_csv('../data/test_data.csv')\r\n",
    "data = df.values\r\n",
    "print(data)\r\n",
    "df.loc[len(df.index)] = [31703, 24591,116859,302925,4256]\r\n",
    "data = df.values\r\n",
    "print(data)\r\n",
    "\r\n",
    "scaler = joblib.load('../model/scaler.pkl')\r\n",
    "pca = joblib.load('../model/pca.pkl')\r\n",
    "\r\n",
    "data_scaled = scaler.fit_transform(data)\r\n",
    "print('data_scaled')\r\n",
    "print(data_scaled)\r\n",
    "\r\n",
    "pca = PCA(n_components=2)\r\n",
    "data_pca = pca.fit_transform(data_scaled)\r\n",
    "print(data_pca)\r\n",
    "\r\n",
    "for i in range(len(data_pca)):\r\n",
    "    d = data_pca[i].reshape(1, -1)\r\n",
    "    print(\"d=\", d)\r\n",
    "    s = keans.predict(d)\r\n",
    "    print(\"s =\", s)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_scaled\n",
      "[[-0.90103373  2.22188671 -0.1525839   2.15167392 -1.22817505]]\n",
      "data_pca\n",
      "[[2.4502773  2.43025843]]\n",
      "param= [[2.4502773  2.43025843]]\n",
      "s= [1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\r\n",
    "from sklearn.metrics import silhouette_score\r\n",
    "from sklearn.decomposition import PCA\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from matplotlib import colors as mcolors\r\n",
    "import joblib\r\n",
    "\r\n",
    "\r\n",
    "keans = joblib.load('../model/kmeans_model.pkl')\r\n",
    "\r\n",
    "scaler = joblib.load('../model/scaler.pkl')\r\n",
    "pca = joblib.load('../model/pca.pkl')\r\n",
    "\r\n",
    "data = [[31703, 24591,116859,302925,4256]]\r\n",
    "\r\n",
    "data_scaled = scaler.transform(data)\r\n",
    "print('data_scaled')\r\n",
    "print(data_scaled)\r\n",
    "\r\n",
    "data_pca = pca.transform(data_scaled)\r\n",
    "print('data_pca')\r\n",
    "print(data_pca)\r\n",
    "\r\n",
    "param = data_pca[0].reshape(1,-1)\r\n",
    "print(\"param=\", param)\r\n",
    "s = keans.predict(param)\r\n",
    "print(\"s=\",s)\r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "name": "python398jvsc74a57bd0cf435912e9e8aa933f5ba11766e36337d76df5880a66f96005e4a7652a241405"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "cf435912e9e8aa933f5ba11766e36337d76df5880a66f96005e4a7652a241405"
   }
  },
  "orig_nbformat": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}